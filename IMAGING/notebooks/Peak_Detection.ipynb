{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python notebook for post-processing ROI responses.\n",
    "# Peak counting in the results data.\n",
    "Assumes folder directory structure:\n",
    "<pre><code>  IMAGING\n",
    "    image_stacks\n",
    "    notebooks\n",
    "    results\n",
    "</code></pre>\n",
    "Execute the code sequentially, one block at a time, using &lt;shift-return&gt;.\n",
    "#### Initialize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import signal\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# global variables\n",
    "if os.name == \"nt\":\n",
    "    FILE_SEP = \"\\\\\"\n",
    "else:\n",
    "    FILE_SEP = \"/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a results directory and peak counting options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# global variables\n",
    "results_sel = \"\"  # the selected results directory\n",
    "stim_start = 100  # analysis start frame\n",
    "stim_done = 250   # analysis end frame\n",
    "\n",
    "pk_options = (0,0)\n",
    "calc_latency = False\n",
    "slope_type = 0\n",
    "num_std = 0\n",
    "baseline = (0,0)\n",
    "\n",
    "s = {'description_width':'200px'} # a default widget style\n",
    "\n",
    "# create results directory widget\n",
    "result_dirs = sorted([f.split(FILE_SEP)[-2] for f in glob.glob(\"../results/*/\", recursive=False)], key=str.casefold)\n",
    "results_widget = widgets.Select(options=result_dirs, description='Results dir', \n",
    "                            disabled=False, layout=widgets.Layout(width='400px'))\n",
    "# create numeric input widgets\n",
    "stim_start_widget = widgets.BoundedIntText(value=stim_start, min=0, max=1000, step=1,\n",
    "                    description='Stimulation start frame', disabled=False, layout={'width':'270px'}, style=s)\n",
    "stim_done_widget = widgets.BoundedIntText(value=stim_done, min=0, max=1000, step=1,\n",
    "                    description='Stimulation done frame', disabled=False, layout={'width':'270px'}, style=s)\n",
    "\n",
    "# create status widget\n",
    "status_widget = widgets.HTML(value=' ', description=' ')\n",
    "\n",
    "# create sensitivity widget\n",
    "sensitivity_widget = widgets.Dropdown(\n",
    "    options=[('low',(0.06,4)),('low-medium',(0.05,6)),('medium',(0.04,7)),('high-medium',(0.03,8)),('high',(0.02,9))],\n",
    "    value=(0.04,7),\n",
    "    description='Peak counting sensitivity:',\n",
    "    disabled=False,\n",
    "    layout={'width':'350px'}, style={'description_width':'180px'}\n",
    ")\n",
    "#create latency widget\n",
    "latency_widget = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Calculate stimulation response latency details',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "# create type of slope calculation widget\n",
    "slope_widget = widgets.Dropdown(\n",
    "    options = [('simple difference',(1)),('three-neighbour',(2)),('polynomial fit',(3)),('gaussian fit',(4))],\n",
    "    value = 1,\n",
    "    description='Slope calculation method:',\n",
    "    disabled = False,\n",
    "    layout={'width':'350px'}, style = {'description_width':'180px'}\n",
    ")\n",
    "# create number of standard deviations widget\n",
    "std_widget = widgets.Dropdown(\n",
    "    options = [('1',(1)),('2',(2)),('3',(3)),('4',(4)),('5',(5)),('6',(6)),('7',(7))],\n",
    "    value = 2,\n",
    "    description = 'Threshold standard deviations:',\n",
    "    disabled = False,\n",
    "    layout={'width':'260px'}, style = {'description_width':'200px'}\n",
    ")\n",
    "# display and respond to the widgets\n",
    "def f(w1, w2, w3, w4, w5, w6, w7, w8):\n",
    "  global results_sel\n",
    "  global stim_start, stim_done\n",
    "  global pk_options, calc_latency, slope_type, num_std, baseline\n",
    "  results_sel = results_widget.value\n",
    "  stim_start = stim_start_widget.value\n",
    "  stim_done = stim_done_widget.value\n",
    "\n",
    "  if not results_sel:\n",
    "    status_widget.value = \"No result directory selected.\"\n",
    "  else:\n",
    "    status_widget.value = \"Selection OK.\"\n",
    "\n",
    "  pk_options = sensitivity_widget.value\n",
    "  calc_latency = latency_widget.value\n",
    "  slope_type = slope_widget.value\n",
    "  num_std = std_widget.value\n",
    "display(widgets.interactive(f, w1=results_widget, w2=status_widget,\n",
    "                           w3=stim_start_widget, w4=stim_done_widget,\n",
    "                           w5=sensitivity_widget, w6=latency_widget, w7=slope_widget, w8 = std_widget))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peak counting over all regions.\n",
    "- The stimulation zone is marked with a white background color\n",
    "- Peak points are marked with black color\n",
    "- If latency is calculated:\n",
    " - latency response start points are marked with red color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def poly(x, a, b , c):\n",
    "    return a * x + b * x**2 + c\n",
    "def gauss(x, a, x0, sigma, y0):\n",
    "    return y0 + (a * np.exp(-(x - x0)**2/(2*sigma**2)))\n",
    "\n",
    "# get the regions and data labels in the selected results directory\n",
    "results_dir = \"../results/\" + results_widget.value\n",
    "region_files = os.listdir(results_dir)\n",
    "region_files = sorted([f for f in region_files if f.startswith(\"region\") and '.csv' in f])\n",
    "\n",
    "# delete any previous results\n",
    "for f in glob.glob(results_dir + \"/peaks_*.csv\"): os.remove(f)  \n",
    "for f in glob.glob(results_dir + \"/peaks_*.pdf\"): os.remove(f)\n",
    "\n",
    "with open(\"../results/\" + results_widget.value + \"/labels.txt\") as f:\n",
    "  data_labels = f.readlines()\n",
    "data_labels = [x.strip() for x in data_labels] \n",
    "\n",
    "p = 2000         # desired length of resampled data\n",
    "pkall = []       # the number of peaks across all stimulus zones regions\n",
    "fpks = []        # first peak values           \"               \"\n",
    "latencies = []   # latencies                   \"               \"\n",
    "rise_times = []  # rise times                  \"               \"\n",
    "max_slopes = []  # maximum slopes              \"               \"\n",
    "zone_areas = []  # area under curve            \"               \"\n",
    "max_vals = []    # maximum values              \"               \"\n",
    "\n",
    "plt.close('all')\n",
    "for r in region_files:     # for each region\n",
    "  fig, ax = plt.subplots(nrows=1, ncols=1, figsize = [15,4])\n",
    "  ax.grid(b=True)\n",
    "\n",
    "  region = r.split('_')[-1].split('-')[0]  # get the region number\n",
    "  A = np.transpose(np.genfromtxt(\"../results/\" + results_sel + \"/\" + r, delimiter=','))\n",
    "\n",
    "  tmin = np.min(A[0])      # start time\n",
    "  tmax = np.max(A[0])      # finish time\n",
    "  trng = tmax-tmin         # time range\n",
    "  tstp = A[0,1]-A[0,0]     # time step\n",
    "  dmin = np.min(A[1:])     # minimum data value (over all traces)\n",
    "  dmax = np.max(A[1:])     # maximum data value\n",
    "  drng = dmax-dmin         # data range\n",
    "  X0 = A[0]                # the time axis\n",
    "  Y0 = (A[1:]-dmin) / drng # data axis, normalized to range(0, 1.0)\n",
    "\n",
    "  sr = p / trng   # the sample rate\n",
    "  pk = []\n",
    "  pts = []\n",
    "\n",
    "  fpk = []      # first peak values     for this region\n",
    "  lats = []     #    latencies       per stimulation zone, for this region\n",
    "  riss = []     #    rise times          \"                  \"\n",
    "  slps = []     #  maximum slopes        \"                  \"\n",
    "  zars = []     # area under curve       \"                  \"\n",
    "  maxs = []     # maximum values         \"                  \"\n",
    "  for idx,y in enumerate(Y0): # for each trace\n",
    "    f = interp1d(X0, y, kind='cubic')                     # define the resampling function\n",
    "    X = np.linspace(tmin, tmax, p+1, endpoint=True)       # define the new time steps\n",
    "    Y = f(X)                                              # resample the original signal\n",
    "\n",
    "    # apply high-pass filter to eliminate the stimulation \"bump\" in the data\n",
    "    sos = signal.butter(3, 0.1, btype='highpass', fs=sr, output='sos')\n",
    "    Yf = signal.sosfiltfilt(sos, Y) # zero phase shift filter\n",
    "\n",
    "    # apply low-pass filter to smooth out higher frequencies in the data\n",
    "    sos = signal.butter(pk_options[1], 2.0, btype='lowpass', fs=sr, output='sos')\n",
    "    Yf = signal.sosfiltfilt(sos, Yf) # zero phase shift filter\n",
    "\n",
    "    # find all the peaks\n",
    "    pks,_ = signal.find_peaks(Yf,prominence=pk_options[0])    # find indices of peaks in the resampled, filtered data\n",
    "    pidx = np.around((A.shape[1]-1)*pks/p).astype(int)        # convert to indices in the original data\n",
    "    pidx = [p for p in pidx if p>=stim_start and p<stim_done] # eliminate peaks outside the stimulation zone\n",
    "    pk.append(len(pidx))                                       # save the number of peaks\n",
    "    pts.append([A[0,pidx], A[idx+1,pidx]])                    # save the peaks as points in the original data\n",
    "\n",
    "    ax.plot(A[0],A[idx+1],label=str(data_labels[idx]))    # plot the original data\n",
    "    ax.plot(pts[-1][0],pts[-1][1],'k.')                   # plot the peak locations\n",
    "\n",
    "    if calc_latency: # analyse \"noise\" in the region before stimulation (for latency calculation)\n",
    "      signal_avg = np.mean(A[idx+1,0:stim_start])   # dc component of noisy signal\n",
    "      noise = A[idx+1,0:stim_start] - signal_avg    # ac     \"        \"\n",
    "      thresh = signal_avg + num_std * np.std(noise)  # latency threshold value\n",
    "      mthresh = signal_avg - num_std * np.std(noise) # mirror threshold value around signal_avg \n",
    "\n",
    "      idxf = -1      # first peak index for this zone     \n",
    "      idxl = -1      # latency start index for this zone \n",
    "      if len(pidx) > 0:                       # any peaks?\n",
    "        idxf = pidx[0]                        # save the first peak index\n",
    "        for i in range(stim_start, stim_done): # find latency start point\n",
    "          if A[idx+1,i] >= thresh:            # above the threshold?\n",
    "            ax.plot(A[0,i],A[idx+1,i],'r.')   # plot the latency start location\n",
    "            idxl = i                          # save \n",
    "            break\n",
    "      fpk.append(A[idx+1,idxf] if idxf!=-1 else 0)  # save first peak value\n",
    "\n",
    "      lat = 0             # latency\n",
    "      ris = 0             # rise time\n",
    "      slp = 0             # max slope\n",
    "      if (idxf != -1) and (idxl != -1):\n",
    "        lat = A[0,idxl] - A[0,stim_start] # save latency time\n",
    "        ris = A[0,idxf] - A[0,idxl]       # save rise time\n",
    "        x_vals = A[0,idxl:idxf+1]\n",
    "        y_vals = A[idx+1,idxl:idxf+1]\n",
    "        if slope_type == 1:      # Simple difference calculations\n",
    "          for i in range(len(x_vals)-1):\n",
    "            sl = (y_vals[i+1] - y_vals[i]) / (x_vals[i+1] - x_vals[i])\n",
    "            if sl > slp:\n",
    "              slp = sl\n",
    "        if slope_type == 2:      # Three neighbour numerical calculations\n",
    "          if len(x_vals) > 5:\n",
    "            for j in range(3, len(x_vals) - 3):\n",
    "              sls = []\n",
    "              for k in range(1,4):\n",
    "                y1 = y_vals[j - k]\n",
    "                y2 = y_vals[j + k]\n",
    "                x1 = x_vals[j - k]\n",
    "                x2 = x_vals[j + k]\n",
    "                sls.append((y2 - y1) / (x2 - x1))\n",
    "              sl = np.mean(sls)\n",
    "              if sl > slp:\n",
    "                slp = sl\n",
    "        if slope_type == 3:       # Polynomial fit calculations\n",
    "          if len(x_vals) > 3:\n",
    "            popt, pcov = curve_fit(poly, x_vals, y_vals)\n",
    "            fitted_y_vals = poly(x_vals, *popt)\n",
    "            #ax.plot(x_vals,fitted_y_vals,'r')\n",
    "            if len(fitted_y_vals) > 3:\n",
    "              for i in range (1, len(fitted_y_vals)):\n",
    "                sl = (fitted_y_vals[i] - fitted_y_vals[i - 1]) / (x_vals[i] - x_vals[i - 1])\n",
    "                if sl > slp:\n",
    "                  slp = sl\n",
    "        if slope_type == 4:     # Gaussian fit calculations\n",
    "          x_vals = A[0,idxl:idxf+1+len(x_vals)]     # extend selection of values to be symetrical aroung the peak\n",
    "          y_vals = A[idx+1,idxl:idxf+1+len(y_vals)]   #\n",
    "          if len(x_vals) > 6:\n",
    "            mean = sum(x_vals * y_vals) / len(x_vals)\n",
    "            sigma = sum(y_vals * (x_vals - mean)**2) / len(x_vals)\n",
    "            y0 = thresh\n",
    "            popt, pcov = curve_fit(gauss, x_vals, y_vals, p0=[max(y_vals),mean,sigma,y0],maxfev = 5000)\n",
    "            fitted_y_vals = gauss(x_vals, *popt)\n",
    "            #ax.plot(x_vals,fitted_y_vals,'r')\n",
    "            peak_index = np.where(fitted_y_vals == np.max(fitted_y_vals))      # Find where peak of gaussian curve\n",
    "            for i in range(1, int(peak_index[0])):                             # Find slopes up to peak of gaussian curve\n",
    "              sl = (fitted_y_vals[i] - fitted_y_vals[i - 1]) / (x_vals[i] - x_vals[i - 1])\n",
    "              if sl > slp:\n",
    "                slp = sl\n",
    "        \n",
    "      lats.append(lat)\n",
    "      riss.append(ris)\n",
    "      slps.append(slp)        \n",
    "    zars.append(np.trapz(A[idx+1,stim_start:stim_done] - signal_avg, A[0,stim_start:stim_done]))   # calculate and save area under curve\n",
    "    maxs.append(np.amax(A[idx+1,stim_start:stim_done]))\n",
    "\n",
    "  pkall.append(pk)         # save  the number of peaks across all regions\n",
    "  fpks.append(fpk)         #  \"      first peaks        \"\n",
    "  latencies.append(lats)   #  \"      latencies          \"\n",
    "  rise_times.append(riss)  #  \"     rise times          \"\n",
    "  max_slopes.append(slps)  #  \"     maximum slopes      \"\n",
    "  zone_areas.append(zars)  #  \"    area under curve     \"\n",
    "  max_vals.append(maxs)    #  \"     maximum vlaues      \"\n",
    "\n",
    "  ax.legend()\n",
    "  ax.set_title(\" amplitude peaks - region \" + region)\n",
    "  \n",
    "  xlab = \"time (s)\\n peak counts: \" + str(pk)\n",
    "  xlab += (\", areas: [\"+', '.join(['%.3g']*len(zars))+\"]\") % tuple(zars)\n",
    "  xlab += (\", max vals: [\"+', '.join(['%.3g']*len(maxs))+\"]\") % tuple(maxs)\n",
    "  if calc_latency:\n",
    "    xlab += (\",\\nlatencies: [\"+', '.join(['%.3g']*len(lats))+\"]\") % tuple(lats)\n",
    "    xlab += (\", rise times: [\"+', '.join(['%.3g']*len(riss))+\"]\") % tuple(riss)\n",
    "    xlab += (\",\\nfirst peak vals: [\"+', '.join(['%.3g']*len(fpk))+\"]\") % tuple(fpk)\n",
    "    xlab += (\", max slopes: [\"+', '.join(['%.3g']*len(slps))+\"]\") % tuple(slps)\n",
    "  ax.set(xlabel=xlab)\n",
    "  ax.set(ylabel=\"%F/F0\")\n",
    "\n",
    "  # grey out plot areas not in any zone\n",
    "  ax.set_facecolor('0.8')\n",
    "  ax.fill((A[0,stim_start],A[0,stim_done],A[0,stim_done],A[0,stim_start]),(dmin,dmin,dmax,dmax),'1.0')\n",
    "\n",
    "  # save figure to pdf\n",
    "  fig.savefig(\"../results/\" + results_widget.value +'/' + \"peaks\" + \"_region_\" + region + \".pdf\", bbox_inches='tight')\n",
    "  plt.show()\n",
    "  plt.close() # frees up memory\n",
    "\n",
    "  # save peak point locations to CSV file\n",
    "  with open (\"../results/\" + results_widget.value +'/' + \"peaks\" + \"_region_\" + region + \".csv\", 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for trace in pts:                                      # for each trace...\n",
    "      for pt in np.transpose(np.array(trace)):             #   for each point...\n",
    "        writer.writerow('{:.3g}'.format(x) for x in pt)    #     save the point (time and intensity)\n",
    "        \n",
    "# save peak count and optional latency summary to CSV file\n",
    "with open (\"../results/\" + results_widget.value + \"/peaks_latencies_summary.csv\", 'w') as file:\n",
    "  writer = csv.writer(file)\n",
    "  if calc_latency: \n",
    "    writer.writerow((\"region number\", \"peak counts\", \"areas\", \"maximum values\", \"latencies\", \"rise times\", \"first peak values\", \"maximum slopes\"))\n",
    "  else: \n",
    "    writer.writerow((\"region number\", \"peak counts\", \"areas\", \"maximum values\"))\n",
    "  for i in range(len(pkall)):\n",
    "    r = ([i+1], pkall[i], zone_areas[i], max_vals[i], latencies[i], rise_times[i], fpks[i], max_slopes[i])\n",
    "    writer.writerow('{:.3g}'.format(x) for x in tuple(np.concatenate(r))) \n",
    "     \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
