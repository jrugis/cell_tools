{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Python notebook for analyzing CPA Experiment CSV file data\n",
    "Assumes folder directory structure:\n",
    "<pre><code>  IMAGING\n",
    "    image_stacks\n",
    "    notebooks\n",
    "    results\n",
    "</code></pre>\n",
    "NOTE: Looks for data files in the results directory.<br>\n",
    "Execute the code sequentially, one block at a time, using &lt;shift-return&gt;."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "from ipywidgets import interact, Layout\n",
    "import ipywidgets as widgets\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import signal\n",
    "from scipy.optimize import curve_fit, OptimizeWarning\n",
    "import math\n",
    "import warnings\n",
    "# global variables\n",
    "if os.name == \"nt\":\n",
    "    FILE_SEP = \"\\\\\"\n",
    "else:\n",
    "    FILE_SEP = \"/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select data files for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create widget for selecting CSV files for analysis\n",
    "file_names = []\n",
    "for file in sorted([f.split(FILE_SEP)[-1] for f in glob.glob(\"../results/*\", recursive=False)], key=str.casefold):\n",
    "    file_names.append(file[:-8]) # Remove \"Results\" from end of file names\n",
    "data_files_widget = widgets.SelectMultiple(options=file_names, description = 'Data Files',\n",
    "                                          disabled=False, layout={'width':'400px'}, style={'description_width':'100px'})\n",
    "display(data_files_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new analysis results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results_dirs = []\n",
    "data_files = []\n",
    "selected_files = data_files_widget.value\n",
    "for file in selected_files:\n",
    "    if not os.path.exists(\"../results/\" + file + \" Results\" + \"/Analysis_Results\"):\n",
    "        os.mkdir(\"../results/\" + file + \" Results\" + \"/Analysis_Results\")\n",
    "    results_dirs.append(\"../results/\" + file + \" Results\" + \"/Analysis_Results\")\n",
    "for i in range(0,len(results_dirs)):\n",
    "    data_files.append(results_dirs[i] + \"/\" + \"_TOTAL-stimALL.csv\")\n",
    "print(\"Done.\") # Inform User that codeblock is done running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose which region columns to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# Global variables\n",
    "data_cols=[]\n",
    "\n",
    "selected_files = data_files_widget.value\n",
    "avg_incl = True\n",
    "link_zones = False\n",
    "automatic_removal = False\n",
    "\n",
    "# Create region columns widgets\n",
    "columns_widgets = [widgets.SelectMultiple(options=[], description='Region cols',\n",
    "                            disabled=False, layout={'width':'160px', 'height':'120px'}, style={'description_width':'100px'})\n",
    "                   for i in range(0,len(selected_files))]\n",
    "# Create included widgets\n",
    "included_widgets = [widgets.Checkbox(value=avg_incl, description='Includes an Avg Col',\n",
    "                                  disabled=False, indent=False)\n",
    "                    for i in range(0,len(selected_files))]\n",
    "# Create label widgets\n",
    "label_widgets = [widgets.Label(\"Columns to analyze for \" + selected_files[i] + \":\") \n",
    "                 for i in range(0,len(selected_files))]\n",
    "\n",
    "print(\"Note that by default all columns are selected for each data file\")\n",
    "for i in range(0,len(selected_files)):\n",
    "    with open(\"../results/\" + selected_files[i] + \" Results/\" + selected_files[i] + \"_TOTAL-stimALL.csv\") as f:\n",
    "        cols = (np.genfromtxt(f,dtype=float,delimiter=',')).shape[1]\n",
    "    columns_widgets[i].options = range(1,cols)\n",
    "    columns_widgets[i].value = columns_widgets[i].options\n",
    "    col_widg = widgets.VBox(children=[label_widgets[i],columns_widgets[i],included_widgets[i]])\n",
    "    display(col_widg)\n",
    "    \n",
    "# Widget to ask use if want to use the same stimulation zones\n",
    "link_widget = widgets.Checkbox(value=link_zones, description='Check this box to make stimulation zones are same for all files',\n",
    "                               disabled=False, indent=False, layout={'width':'400px'})\n",
    "automatic_removal_widget = widgets.Checkbox(value=automatic_removal, description='Check this box to automatically remove bad traces',\n",
    "                               disabled=False, indent=False, layout={'width':'400px'})\n",
    "print(\"OPTION TO MAKE STIMULATION ZONES SAME FOR ALL FILES\")\n",
    "display(link_widget)\n",
    "print(\"OPTION TO AUTOMATICALLY REMOVE BAD TRACES\")\n",
    "display(automatic_removal_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Global variables\n",
    "A0s = []\n",
    "full_cols = []\n",
    "avg_col_indexs = []\n",
    "link_zones = link_widget.value\n",
    "automatic_removal = automatic_removal_widget.value\n",
    "# Number of anomaly zones widgets\n",
    "num_anomaly_widgets = [widgets.Dropdown(options=['0','1','2','3','4','5','6'],\n",
    "                                        value='0',\n",
    "                                        description = 'Number of anomalies present in ' + selected_files[i] + ':',\n",
    "                                        disabled=False,\n",
    "                                        layout={'width':'650px'}, style={'description_width':'600px'})\n",
    "                       for i in range(0,len(selected_files))]\n",
    "if link_zones == False:\n",
    "    # Number of stimulation zones widgets\n",
    "    num_stim_widgets = [widgets.Dropdown(options=['1','2','3','4','5','6'], value='1',\n",
    "                                         description = 'Number of stimulation time zones for ' + selected_files[i] + ':',\n",
    "                                         disabled=False,\n",
    "                                         layout={'width':'650px'}, style={'description_width':'600px'})\n",
    "                        for i in range(0,len(selected_files))]\n",
    "else:\n",
    "    num_stim_widget = widgets.Dropdown(options=['1','2','3','4','5','6'], value='1',\n",
    "                                       description = 'Number of stimulation time zones for all plots: ',\n",
    "                                       disabled=False, layout={'width':'650px'}, style={'description_width':'600px'})\n",
    "\n",
    "out = widgets.Output()\n",
    "plt.close('all')\n",
    "for i in range(0,len(selected_files)):\n",
    "    # Checking that atleast one column has been selected\n",
    "    check = np.size(columns_widgets[i].value)\n",
    "    if not check:\n",
    "        print(\"One of your selected data files does not have any columns selected for analysis\")\n",
    "        break\n",
    "        \n",
    "    # Global variables\n",
    "    cols = np.array(columns_widgets[i].value)\n",
    "   \n",
    "    with open(\"../results/\" + selected_files[i] + \" Results/\" + selected_files[i] + \n",
    "              \"_TOTAL-stimALL.csv\", 'r', encoding='utf-8-sig') as f:\n",
    "        A0 = np.transpose(np.genfromtxt(f,dtype=float,delimiter=','))\n",
    "        A0s.append(A0)\n",
    "    # Removing bad traces from analysis sets\n",
    "    if automatic_removal == True:\n",
    "        removal_idx = np.argwhere(np.any(A0[:,1:] == 0, axis = 1))\n",
    "        \n",
    "        # Checking to make sure bad traces aren't just an artifact/anomaly\n",
    "        if len(removal_idx) > int(.5 * len(cols)):\n",
    "            removal_times = []\n",
    "            for idx in removal_idx:\n",
    "                removal_times.append(np.where(A0[idx][:] == 0)[1][0])\n",
    "            if np.max(removal_times) - np.min(removal_times) > 3:\n",
    "                cols = np.delete(cols,removal_idx-1) # Removing ROIS with bad traces\n",
    "        else:\n",
    "            cols = np.delete(cols,removal_idx-1) # Removing ROIS with bad traces\n",
    "    full_cols.append(cols)    \n",
    "        \n",
    "    tmin = np.min(A0[0]) # Start time\n",
    "    tmax = np.max(A0[0]) # Finish time\n",
    "    \n",
    "    dmin = np.amin(A0[cols]) # Minimum Y-value\n",
    "    dmax = np.amax(A0[cols]) # Maximum Y-value\n",
    "    \n",
    "    # Creating and displaying anomaly widgets below each plot\n",
    "    if link_zones == False:\n",
    "        widg = widgets.VBox(children=[out,num_anomaly_widgets[i],num_stim_widgets[i]])\n",
    "        display(widg)\n",
    "    else:\n",
    "        widg = widgets.VBox(children=[out,num_anomaly_widgets[i]])\n",
    "        display(widg)\n",
    "    with out:\n",
    "        fig, ax = plt.subplots(ncols=1,nrows=1,figsize=(20,3), constrained_layout=True)\n",
    "        ax.set_title(selected_files[i])\n",
    "        ax.set(ylabel=\"340nm/380nm\")\n",
    "        ax.set(xlabel=\"time (s)\")\n",
    "        ax.plot(A0[0],np.transpose(A0[cols]))\n",
    "        if len(columns_widgets[i].value) < 11:\n",
    "            ax.legend(columns_widgets[i].value, title='region', fontsize=8)\n",
    "        plt.show()\n",
    "        plt.close() # Frees up memory\n",
    "    out = widgets.Output()\n",
    "if link_zones == True:\n",
    "    display(num_stim_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly/Artifact Removal Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Anomaly/Artifact removal\n",
    "# Global variables\n",
    "anomaly_present = False\n",
    "anomaly_files = []\n",
    "anomaly_A0s = []\n",
    "anomaly_cols = []\n",
    "num_anomaly = []\n",
    "plt.close('all')\n",
    "# Checking if any anomalies are present\n",
    "for i in range(0,len(selected_files)):\n",
    "    if int(num_anomaly_widgets[i].value) != 0:\n",
    "        anomaly_present = True\n",
    "        num_anomaly.append(num_anomaly_widgets[i].value)\n",
    "        anomaly_files.append(selected_files[i])\n",
    "        anomaly_A0s.append(A0s[i])\n",
    "        anomaly_cols.append(full_cols[i])\n",
    "# If anomalies are present, begin anomaly removal\n",
    "if anomaly_present == True:\n",
    "        out = widgets.Output()\n",
    "        # Anomaly removal widget\n",
    "        anomaly_widgets = [] # Anomaly time zones\n",
    "        labels = []\n",
    "        # Update anomaly zone widgets based on number of zones value\n",
    "        for i in range(0,len(anomaly_files)):\n",
    "            # Local Variables\n",
    "            tmin = np.min(anomaly_A0s[i][0]) # Start time\n",
    "            tmax = np.max(anomaly_A0s[i][0]) # Finish time\n",
    "            \n",
    "            dt = int(tmax-tmin) / int(num_anomaly[i])\n",
    "            # Create label widgets\n",
    "            label_widgets = [widgets.Label(\"Anomaly zone \" + str(j+1) + \":\") \n",
    "                             for j in range(0,int(num_anomaly[i]))]\n",
    "            labels.append(label_widgets) # Adding labels to total lsit so they can be accessed later\n",
    "            anomaly_zones = [widgets.IntRangeSlider(value=(tmin + (j*dt), tmin + (j+1)*dt),\n",
    "                                                    min=tmin, max=tmax,\n",
    "                                                    step=1, description=\" \",\n",
    "                                                    disabled=False, continuous_update=False, \n",
    "                                                    orientation='horizontal', readout=True,\n",
    "                                                    readout_format='d', layout={'width':'1460px'},\n",
    "                                                    style={'description_width':'95px'})\n",
    "                             for j in range(0,int(num_anomaly[i]))]\n",
    "            anomaly_widgets.append(anomaly_zones) # Adding anomaly widgets to total list so they can be accessed later  \n",
    "            fig, ax = plt.subplots(ncols=1,nrows=1,figsize=(20,3), constrained_layout=True)\n",
    "            ax.set_title(anomaly_files[i])\n",
    "            ax.set(ylabel=\"340nm/380nm\")\n",
    "            ax.set(xlabel=\"time (s)\")\n",
    "            ax.plot(anomaly_A0s[i][0],np.transpose(anomaly_A0s[i][anomaly_cols[i]]))\n",
    "            if len(anomaly_cols[i]) < 11:\n",
    "                ax.legend(anomaly_cols[i], title='region', fontsize=8)\n",
    "            plt.show()\n",
    "            plt.close() # Frees up memory\n",
    "            # Display each zone widget for each particular file\n",
    "            for j in range(0,len(anomaly_widgets[i])):\n",
    "                display(labels[i][j])\n",
    "                display(anomaly_widgets[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly/Artifact Removal Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displaying zones selected for anomaly removal\n",
    "if anomaly_present == True:\n",
    "    %matplotlib inline\n",
    "    plt.close('all')\n",
    "    for i in range(0,len(anomaly_files)):\n",
    "        # Local variables\n",
    "        tmin = np.min(anomaly_A0s[i][0]) # Start time\n",
    "        tmax = np.max(anomaly_A0s[i][0]) # Finish time\n",
    "    \n",
    "        dmin = np.amin(anomaly_A0s[i][anomaly_cols[i]])\n",
    "        dmax = np.amax(anomaly_A0s[i][anomaly_cols[i]])\n",
    "        a_zn = []\n",
    "        for j in range(0,len(anomaly_widgets[i])):\n",
    "            a_zn.append(anomaly_widgets[i][j].value)\n",
    "        # Global variables\n",
    "        a_zn = np.array(a_zn)\n",
    "        \n",
    "        fig,ax = plt.subplots(ncols=1,nrows=1,figsize=(13,3), constrained_layout=True)\n",
    "        ax.set_title(str(len(a_zn)) + \"x anomaly time zone ranges in \" + anomaly_files[i])\n",
    "        ax.set(ylabel=\"340/380nm\")\n",
    "        ax.set(xlabel=\"time (s)\")\n",
    "        # Grey out plot areas not in any zone\n",
    "        ax.set_facecolor('0.8')\n",
    "        for z in a_zn:\n",
    "            ax.fill((z[0],z[1],z[1],z[0]),(dmin,dmin,dmax,dmax),'1.0')\n",
    "        ax.plot([a_zn[:,0],a_zn[:,0]],[dmin,dmax],color='0.8') # grey vertical lines in case zones overlap\n",
    "        ax.plot([a_zn[:,1],a_zn[:,1]],[dmin,dmax],color='0.8')\n",
    "        ax.plot(anomaly_A0s[i][0],np.transpose(anomaly_A0s[i][anomaly_cols[i]]))\n",
    "        if len(anomaly_cols[i]) < 11:\n",
    "            ax.legend(anomaly_cols[i], title='region', fontsize=8)\n",
    "        plt.show()\n",
    "        plt.close() # Frees up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly/Artifact Removal Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if anomaly_present == True:\n",
    "    %matplotlib inline\n",
    "    plt.close('all')\n",
    "    def poly(x, a, b, c):\n",
    "        return a * x + b * x**2 + c\n",
    "    for i in range(0,len(anomaly_files)):\n",
    "        # Local variables\n",
    "        tmin = np.min(anomaly_A0s[i][0]) # Start time\n",
    "        tmax = np.max(anomaly_A0s[i][0]) # Finish time\n",
    "        \n",
    "        dmin = np.amin(anomaly_A0s[i][anomaly_cols[i]]) # Maximum Y-value\n",
    "        dmax = np.amax(anomaly_A0s[i][anomaly_cols[i]]) # Minimum Y-value\n",
    "        a_zn = []\n",
    "        X0 = anomaly_A0s[i][0]\n",
    "        csr = (len(X0) - 1) / (tmax-tmin) # Current sample rate\n",
    "        for j in range(0,len(anomaly_widgets[i])):\n",
    "            z0 = int(anomaly_widgets[i][j].value[0] * csr/1) # Adjust selection to match FPS of A0 indexing\n",
    "            z1 = int(anomaly_widgets[i][j].value[1] * csr/1)\n",
    "            a_zn.append([z0,z1])\n",
    "        # Global variables\n",
    "        a_zn = np.array(a_zn)\n",
    "        \n",
    "        for col in anomaly_cols[i]:\n",
    "            Y0 = anomaly_A0s[i][col]\n",
    "            for z in a_zn:\n",
    "                x_vals = [anomaly_A0s[i][0][z[0]],anomaly_A0s[i][0][z[1]]] # Taking x values of start and end points\n",
    "                y_vals = [anomaly_A0s[i][col][z[0]],anomaly_A0s[i][col][z[1]]] # Taking y values of start and end points\n",
    "                coefs = np.polyfit(x_vals,y_vals,1) # Calculating coefficients to use when plotting line\n",
    "                line = np.poly1d(coefs) # Creating line equation used to plot line\n",
    "                anomaly_A0s[i][col][z[0]:z[1]] = line(anomaly_A0s[i][0][z[0]:z[1]]) # Adding new calculated points to original array\n",
    "        fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(13,3), constrained_layout=True)\n",
    "        ax.plot(anomaly_A0s[i][0],np.transpose(anomaly_A0s[i][anomaly_cols[i]]))\n",
    "        plt.show()\n",
    "        plt.close() # Frees up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set stimulation time zone ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Global Variables\n",
    "out = widgets.Output()\n",
    "total_zones = []\n",
    "labels = []\n",
    "plt.close('all')\n",
    "\n",
    "\n",
    "if link_zones == True:\n",
    "    dt = int(tmax-tmin) / int(num_stim_widget.value)\n",
    "    # Create label widgets\n",
    "    label_widgets = [widgets.Label(\"Stimulation zone \" + str(j+1) + \":\") \n",
    "                     for j in range(0,int(num_stim_widget.value))]\n",
    "    stim_zones = [widgets.IntRangeSlider(value=(tmin + (j*dt), tmin + (j+1)*dt),\n",
    "                                             min=tmin, max=tmax,\n",
    "                                             step=1, disabled=False, continuous_update=False, \n",
    "                                             orientation='horizontal', description=\" \", readout=True,\n",
    "                                             readout_format='d', layout={'width':'1460px'},\n",
    "                                             style={'description_width':'95px'})\n",
    "                      for j in range(0,int(num_stim_widget.value))]\n",
    "for i in range(0,len(selected_files)):\n",
    "    if link_zones == False:\n",
    "        # Local Variables\n",
    "        tmin = np.min(A0s[i][0]) # Start time\n",
    "        tmax = np.max(A0s[i][0]) # Finish time\n",
    "        dt = int(tmax-tmin) / int(num_stim_widgets[i].value)\n",
    "        # Create label widgets\n",
    "        label_widgets = [widgets.Label(\"Stimulation zone \" + str(j+1) + \":\") \n",
    "                         for j in range(0,int(num_stim_widgets[i].value))]\n",
    "        labels.append(label_widgets) # Adding labels to total lsit so they can be accessed later\n",
    "        stim_zones = [widgets.IntRangeSlider(value=(tmin + (j*dt), tmin + (j+1)*dt),\n",
    "                                             min=tmin, max=tmax,\n",
    "                                             step=1, disabled=False, continuous_update=False, \n",
    "                                             orientation='horizontal', description=\" \", readout=True,\n",
    "                                             readout_format='d', layout={'width':'1460px'},\n",
    "                                             style={'description_width':'95px'})\n",
    "                      for j in range(0,int(num_stim_widgets[i].value))]\n",
    "        total_zones.append(stim_zones) # Adding widgets to total list so they can be accessed later\n",
    "    fig, ax = plt.subplots(ncols=1,nrows=1,figsize=(20,3), constrained_layout=True)\n",
    "    ax.set_title(selected_files[i])\n",
    "    ax.set(ylabel=\"340nm/380nm\")\n",
    "    ax.set(xlabel=\"time (s)\")\n",
    "    ax.plot(A0s[i][0],np.transpose(A0s[i][full_cols[i]]))\n",
    "    if len(full_cols[i]) < 11:\n",
    "        ax.legend(full_cols[i], title='region', fontsize=8)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    # Making separate plots to save as representative trace pdfs\n",
    "    fig, ax = plt.subplots(ncols=1,nrows=1, figsize=(15,3), constrained_layout=True)\n",
    "    ax.set_title(selected_files[i])\n",
    "    ax.set(ylabel=\"340nm/380nm\")\n",
    "    ax.set(xlabel=\"time (s)\")\n",
    "    ax.plot(A0s[i][0],np.transpose(A0s[i][full_cols[i]]))\n",
    "    ax.set_ylim([0,2.0]) # Manually setting y-axis so same for all plots\n",
    "    if len(full_cols[i]) < 11:\n",
    "        ax.legend(full_cols[i], title='region', fontsize=8)\n",
    "    plt.savefig(results_dirs[i] + \"/full_trace\" + \".pdf\") # Save figure as pdf\n",
    "    plt.close() # Frees up memory\n",
    "    if link_zones == False:\n",
    "        for j in range(0,len(total_zones[i])):\n",
    "            display(labels[i][j])\n",
    "            display(total_zones[i][j]) # Display each zone widget for each particular file\n",
    "if link_zones == True:\n",
    "    for j in range(0,int(num_stim_widget.value)):\n",
    "        display(label_widgets[j])\n",
    "        display(stim_zones[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot data and stimulation time zones\n",
    "- Stimulation zones are marked with a white background color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# If stimulation zones are same, duplicated signal stimulation zone entry for all files\n",
    "if link_zones == True:\n",
    "    for i in range(0,len(selected_files)):\n",
    "        temp_zones = []\n",
    "        for j in range(0,int(num_stim_widget.value)):\n",
    "            temp_zones.append(stim_zones[j])\n",
    "        total_zones.append(temp_zones)\n",
    "\n",
    "# Global variables\n",
    "zn = np.array(total_zones, dtype=object)\n",
    "\n",
    "automatic_baselines = []\n",
    "starting_baselines = []\n",
    "# Filling arrays with initial values\n",
    "for i in range(0,len(selected_files)):\n",
    "    automatic_baselines.append(False)\n",
    "    starting_baselines.append(False)\n",
    "plt.close('all')\n",
    "if link_zones == False:\n",
    "    automatic_baseline_widgets = [widgets.Checkbox(value=False, \n",
    "                                                 description=\"Check this box to have automatic baselines for \" + selected_files[i],\n",
    "                                                 disabled=False,layout={'width':'650px'}, style={'description_width':'600px'},\n",
    "                                                 indent=False,) for i in range(0,len(selected_files))]\n",
    "    starting_baseline_widgets = [widgets.Checkbox(value=False,\n",
    "                                                description=\"Check this box to have starting baseline for \" + selected_files[i],\n",
    "                                                disabled=False,layout={'width':'650px'}, style={'description_width':'600px'},\n",
    "                                                indent=False) for i in range(0,len(selected_files))]\n",
    "    out = widgets.Output()\n",
    "\n",
    "for i in range(0,len(selected_files)):\n",
    "    # Local variables\n",
    "    dmin = np.amin(A0s[i][full_cols[i]]) # Minimum Y-value\n",
    "    dmax = np.amax(A0s[i][full_cols[i]]) # Maximum Y-value\n",
    "    if link_zones == False:\n",
    "        baselines_widg = widgets.VBox(children=[out,automatic_baseline_widgets[i],starting_baseline_widgets[i]])\n",
    "        display(baselines_widg)\n",
    "    else:\n",
    "        baselines_widg = widgets.VBox(children=[out])\n",
    "        display(baselines_widg)\n",
    "    with out:\n",
    "        fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(13,3), constrained_layout=True)\n",
    "        ax.set_title(str(len(zn[i])) + \"x stimulation time zone ranges for \" + selected_files[i])\n",
    "        ax.set(ylabel=\"340/380nm\")\n",
    "        ax.set(xlabel=\"time (s)\")\n",
    "        ax.set_facecolor('0.8') # Grey out plot areas not in any zone\n",
    "        for z in zn[i]:\n",
    "            ax.fill((z.value[0],z.value[1],z.value[1],z.value[0]),(dmin,dmin,dmax,dmax),'1.0')\n",
    "            ax.plot([z.value[0],z.value[0]],[dmin,dmax],color='0.8') # Grey vertical lines in case zones overlap\n",
    "            ax.plot([z.value[1],z.value[1]],[dmin,dmax],color='0.8')\n",
    "        ax.plot(A0s[i][0],np.transpose(A0s[i][full_cols[i]]))\n",
    "        if len(full_cols[i]) < 11:\n",
    "            ax.legend(full_cols[i], title='region', fontsize=8)\n",
    "        plt.show()\n",
    "        plt.close() # Frees up memory\n",
    "    out = widgets.Output()\n",
    "if link_zones == True:\n",
    "    automatic_baseline_widget = widgets.Checkbox(value=False, \n",
    "                                                 description=\"Check this box to have automatic baselines for all\",\n",
    "                                                 disabled=False,\n",
    "                                                 layout={'width':'650px'}, style={'description_width':'600px'},\n",
    "                                                 indent=False)\n",
    "    starting_baseline_widget = widgets.Checkbox(value=False,\n",
    "                                                description=\"Check this box to have starting baseline for all\",\n",
    "                                                disabled=False,\n",
    "                                                layout={'width':'650px'}, style={'description_width':'600px'},\n",
    "                                                indent=False)\n",
    "    def f(w1,w2):\n",
    "        global automatic_baselines, starting_baselines\n",
    "    display(widgets.interactive(f, w1=automatic_baseline_widget, w2=starting_baseline_widget))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Global variables\n",
    "slope_types = []\n",
    "num_stds = []\n",
    "baselines = []\n",
    "base_lengths = []\n",
    "start_lengths = []\n",
    "response_stds = []\n",
    "# Reseting zn in case next code block is run, \n",
    "# and then this one is run again (prevents error)\n",
    "zn = np.array(total_zones, dtype=object)\n",
    "\n",
    "# Filling Global Variable arrays with initial values\n",
    "for i in range(0,len(selected_files)):\n",
    "    slope_types.append(0)\n",
    "    num_stds.append(0)\n",
    "    baselines.append([0,0])\n",
    "    base_lengths.append(0)\n",
    "    start_lengths.append(0)\n",
    "    response_stds.append(0)\n",
    "\n",
    "# create type of slope calculation widgets\n",
    "slope_widgets = [widgets.Dropdown(\n",
    "    options = [('simple difference',(1)),('three-neighbour',(2)),('polynomial fit',(3)),('gaussian fit',(4))],\n",
    "    value = 1,\n",
    "    description='Slope calculation method:',\n",
    "    disabled = False,\n",
    "    layout={'width':'350px'}, style = {'description_width':'180px'}\n",
    ") for i in range(0,len(selected_files))]\n",
    "\n",
    "# create number of standard deviations widgets\n",
    "std_widgets = [widgets.Dropdown(\n",
    "    options = [('1',(1)),('2',(2)),('3',(3)),('4',(4)),('5',(5)),('6',(6)),('7',(7))],\n",
    "    value = 2,\n",
    "    description = 'Threshold standard deviations:',\n",
    "    disabled = False,\n",
    "    layout={'width':'260px'}, style = {'description_width':'200px'}\n",
    ") for i in range(0,len(selected_files))]\n",
    "\n",
    "# create number of standard deviations for response threshold widgets\n",
    "response_std_widgets = [widgets.Dropdown(\n",
    "    options = [('1',(1)),('2',(2)),('3',(3)),('4',(4)),('5',(5)),('6',(6)),('7',(7))],\n",
    "    value = 4,\n",
    "    description = 'Response % standard deviations:',\n",
    "    disabled = False,\n",
    "    layout={'width':'260px'}, style = {'description_width':'200px'}\n",
    ") for i in range(0,len(selected_files))]\n",
    "\n",
    "# create baseline zone widgets\n",
    "baseline_widgets = [widgets.IntRangeSlider(\n",
    "    value=(tmin,tmax), min=tmin, max=tmax, step=5,\n",
    "    description=\"Baseline unstimulated time\"+' (s)',\n",
    "    disabled=False, continuous_update=False, orientation='horizontal',\n",
    "    readout=True, readout_format='d',\n",
    "    layout={'width':'900px'}, style={'description_width':'200px'}\n",
    ") for i in range(0,len(selected_files))]\n",
    "\n",
    "# create automatic baseline length widgets\n",
    "baseline_length_widgets = [widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Length of Automatic Baselines (in seconds):',\n",
    "    layout={'width':'450px'}, style = {'description_width':'250px'},\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ") for i in range(0,len(selected_files))]\n",
    "\n",
    "# create starting baseline length widgets\n",
    "start_length_widgets = [widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Length of Starting Baseline (in seconds):',\n",
    "    layout={'width':'450px'}, style = {'description_width':'250px'},\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ") for i in range(0,len(selected_files))]\n",
    "\n",
    "# Displaying widgets based on previous widget selections\n",
    "if link_zones == True:\n",
    "    # Updating starting_baselines and automatic_baselines arrays\n",
    "    for i in range(0,len(selected_files)):\n",
    "        starting_baselines[i] = starting_baseline_widget.value\n",
    "        automatic_baselines[i] = automatic_baseline_widget.value\n",
    "    plt.close('all')\n",
    "    for i in range(0,len(selected_files)):\n",
    "            dmin = np.amin(A0s[i][full_cols[i]]) # Minimum Y-value\n",
    "            dmax = np.amax(A0s[i][full_cols[i]]) # Maximum Y-value\n",
    "            fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(13,3), constrained_layout=True)\n",
    "            ax.set_title(str(len(zn[i])) + \"x stimulation time zone ranges for \" + selected_files[i])\n",
    "            ax.set(ylabel=\"340/380nm\")\n",
    "            ax.set(xlabel=\"time (s)\")\n",
    "            ax.set_facecolor('0.8') # Grey out plot areas not in any zone\n",
    "            for z in zn[i]:\n",
    "                ax.fill((z.value[0],z.value[1],z.value[1],z.value[0]),(dmin,dmin,dmax,dmax),'1.0')\n",
    "                ax.plot([z.value[0],z.value[0]],[dmin,dmax],color='0.8') # Grey vertical lines in case zones overlap\n",
    "                ax.plot([z.value[1],z.value[1]],[dmin,dmax],color='0.8')\n",
    "            ax.plot(A0s[i][0],np.transpose(A0s[i][full_cols[i]]))\n",
    "            if len(full_cols[i]) < 11:\n",
    "                ax.legend(full_cols[i], title='region', fontsize=8)\n",
    "            plt.show()\n",
    "            plt.close() # Frees up memory\n",
    "    if automatic_baselines[0] == True and starting_baselines[0] == True:\n",
    "        options_widg = widgets.VBox(children=[slope_widgets[0],std_widgets[0],response_std_widgets[0],\n",
    "                                              baseline_length_widgets[0],start_length_widgets[0]])\n",
    "        display(options_widg)\n",
    "    elif automatic_baselines[0] == True:\n",
    "        options_widg = widgets.VBox(children=[slope_widgets[0],std_widgets[0],\n",
    "                                              response_std_widgets[0],baseline_length_widgets[0]])\n",
    "        display(options_widg)\n",
    "    elif starting_baselines[0] == True:\n",
    "        options_widg = widgets.VBox(children=[slope_widgets[0],std_widgets[0],\n",
    "                                              response_std_widgets[0],baseline_widgets[0],start_length_widgets[0]])\n",
    "        display(options_widg)\n",
    "    else:\n",
    "        options_widg = widgets.VBox(children=[slope_widgets[0],std_widgets[0],\n",
    "                                              response_std_widgets[0],baseline_widgets[0]])\n",
    "        display(options_widg)\n",
    "\n",
    "else:\n",
    "    # Updating starting_baselines and automatic_baselines arrays\n",
    "    for i in range(0,len(selected_files)):\n",
    "        starting_baselines[i] = starting_baseline_widgets[i].value\n",
    "        automatic_baselines[i] = automatic_baseline_widgets[i].value\n",
    "    out = widgets.Output()\n",
    "    plt.close('all')\n",
    "    for i in range(0,len(selected_files)):\n",
    "        # Local variables\n",
    "        dmin = np.amin(A0s[i][full_cols[i]]) # Minimum Y-value\n",
    "        dmax = np.amax(A0s[i][full_cols[i]]) # Maximum Y-value\n",
    "        \n",
    "        if automatic_baselines[i] == True and starting_baselines[i] == True:\n",
    "            options_widg = widgets.VBox(children=[out,slope_widgets[i],std_widgets[i],\n",
    "                                                  response_std_widgets[i],baseline_length_widgets[i],start_length_widgets[i]])\n",
    "            display(options_widg)\n",
    "        elif automatic_baselines[i] == True:\n",
    "            options_widg = widgets.VBox(children=[out,slope_widgets[i],std_widgets[i],\n",
    "                                                  response_std_widgets[i],baseline_length_widgets[i]])\n",
    "            display(options_widg)\n",
    "        elif starting_baselines[i] == True:\n",
    "            options_widg = widgets.VBox(children=[out,slope_widgets[i],std_widgets[i],\n",
    "                                                  response_std_widgets[i],baseline_widgets[i],start_length_widgets[i]])\n",
    "            display(options_widg)\n",
    "        else:\n",
    "            options_widg = widgets.VBox(children=[out,slope_widgets[i],\n",
    "                                                  response_std_widgets[i],std_widgets[i],baseline_widgets[i]])\n",
    "            display(options_widg)\n",
    "        with out:\n",
    "            fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(13,3), constrained_layout=True)\n",
    "            ax.set_title(str(len(zn[i])) + \"x stimulation time zone ranges for \" + selected_files[i])\n",
    "            ax.set(ylabel=\"340/380nm\")\n",
    "            ax.set(xlabel=\"time (s)\")\n",
    "            ax.set_facecolor('0.8') # Grey out plot areas not in any zone\n",
    "            for z in zn[i]:\n",
    "                ax.fill((z.value[0],z.value[1],z.value[1],z.value[0]),(dmin,dmin,dmax,dmax),'1.0')\n",
    "                ax.plot([z.value[0],z.value[0]],[dmin,dmax],color='0.8') # Grey vertical lines in case zones overlap\n",
    "                ax.plot([z.value[1],z.value[1]],[dmin,dmax],color='0.8')\n",
    "            ax.plot(A0s[i][0],np.transpose(A0s[i][full_cols[i]]))\n",
    "            if len(full_cols[i]) < 11:\n",
    "                ax.legend(full_cols[i], title='region', fontsize=8)\n",
    "            plt.show()\n",
    "            plt.close() # Frees up memory\n",
    "        out = widgets.Output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot analysis by region\n",
    "- unstimulated time baseline and threshold is marked with light grey color\n",
    "- latency response start points are marked with red color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def poly(x, a, b , c):\n",
    "    return a * x + b * x**2 + c\n",
    "def gauss(x, a, x0, sigma, y0):\n",
    "    return y0 + (a * np.exp(-(x - x0)**2/(2*sigma**2)))\n",
    "\n",
    "# Setting array values to input value if stimulation zones are same\n",
    "if link_zones == True:\n",
    "    for i in range(0,len(selected_files)):\n",
    "        slope_types[i] = slope_widgets[0].value\n",
    "        num_stds[i] = std_widgets[0].value\n",
    "        response_stds[i] = response_std_widgets[0].value\n",
    "        if automatic_baselines[i] == False:\n",
    "            baselines[i] = baseline_widgets[0].value\n",
    "        if automatic_baselines[i] == True:\n",
    "            base_lengths[i] = baseline_length_widgets[0].value\n",
    "        if starting_baselines[i] == True:\n",
    "            start_lengths[i] = start_length_widgets[0].value\n",
    "if link_zones == False:\n",
    "    for i in range(0,len(selected_files)):\n",
    "        slope_types[i] = slope_widgets[i].value\n",
    "        num_stds[i] = std_widgets[i].value\n",
    "        response_stds[i] = response_std_widgets[i].value\n",
    "        if automatic_baselines[i] == False:\n",
    "            baselines[i] = baseline_widgets[i].value\n",
    "        if automatic_baselines[i] == True:\n",
    "            base_lengths[i] = baseline_length_widgets[i].value\n",
    "        if starting_baselines[i] == True:\n",
    "            start_lengths[i] = start_length_widgets[i].value  \n",
    "            \n",
    "# Looping through each file selected\n",
    "for i in range(0,len(selected_files)):\n",
    "    # Local Variables\n",
    "    zn = np.array(total_zones[i])\n",
    "    tmin = np.min(A0s[i][0]) # Start time\n",
    "    tmax = np.max(A0s[i][0]) # Finish time\n",
    "    dmin = np.amin(A0s[i][full_cols[i]]) # Minimum Y-value\n",
    "    dmax = np.amax(A0s[i][full_cols[i]]) # Maximum Y-value\n",
    "    \n",
    "    idx_fpks = []    # First peak indices          Per zone  Per region\n",
    "    idx_lsts = []    # Latency start indices       \"        \"\n",
    "    latencies = []   # Latencies                   \"        \"\n",
    "    rise_times = []  # Rise times                  \"        \"\n",
    "    max_slopes = []  # Maximum slopes              \"        \"\n",
    "    zone_areas = []  # Area under curve            \"        \"\n",
    "    max_vals = []    # Maximum values              \"        \"\n",
    "    unstim_avg = []  # Unstimulated average        \"        \"\n",
    "    responding = []  # Whether max is over response threshold \"    \"\n",
    "    starting_base = np.zeros_like(full_cols[i], dtype = float) # Starting unstimulated average \"    \"\n",
    "    X0 = A0s[i][0]\n",
    "    sr = 6.0 # Desired sample rate\n",
    "    csr = (len(X0) - 1) / (tmax-tmin) # Current sample rate\n",
    "    p = int((sr / csr) * len(X0)) # New number of points\n",
    "    \n",
    "    ##### Adjustment for different data sources ####\n",
    "    if (csr < 1.0):\n",
    "        filter_factor = 0.05\n",
    "        prominence_factor = 3.0\n",
    "    else:\n",
    "        filter_factor = 1.0\n",
    "        prominence_factor = 1.0\n",
    "    ################################################\n",
    "      \n",
    "    # Delete any previous results\n",
    "    for f in glob.glob(results_dirs[i] + \"/.csv\"): os.remove(f)\n",
    "    for f in glob.glob(results_dirs[i] + \"/.pdf\"): os.remove(f)\n",
    "    for f in glob.glob(results_dirs[i] + \"/.png\"): os.remove(f)\n",
    "    plt.close('all') # Frees up memory\n",
    "    \n",
    "    for col in full_cols[i]: # For each region...\n",
    "        if automatic_baselines[i] == True:\n",
    "            baseline_avgs = []\n",
    "        dmin = np.amin(A0s[i][col])\n",
    "        dmax = np.amax(A0s[i][col])\n",
    "        \n",
    "        Y0 = A0s[i][col]\n",
    "        Y1 = (Y0-dmin) / (dmax-dmin) # data axis, normalized to range(0,1.0)\n",
    "\n",
    "        # Initialise the region plot\n",
    "        fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(15,3), constrained_layout=True)\n",
    "        ax.grid(visible=True)\n",
    "        if included_widgets[i].value == True and col == max(full_cols[i]):\n",
    "            ax.set_title(\"Peaks: Average file \" + selected_files[i])\n",
    "        else:\n",
    "            ax.set_title(\"Peaks: region \" + str(col) + \" file \" + selected_files[i])\n",
    "        ax.set(ylabel=\"340/380nm\")\n",
    "        \n",
    "        # Grey out plot areas not in any zone\n",
    "        ax.set_facecolor('0.8')\n",
    "        for z in zn:\n",
    "            ax.fill((z.value[0],z.value[1],z.value[1],z.value[0]),(dmin,dmin,dmax,dmax),'1.0')\n",
    "            ax.plot([z.value[0],z.value[0]],[dmin,dmax],color='0.8') # Grey vertical lines in case zones overlap\n",
    "            ax.plot([z.value[1],z.value[1]],[dmin,dmax],color='0.8')\n",
    "            \n",
    "        # Plot baseline region marking\n",
    "        # Analyze \"noise\" in the baseline region (for latency calculation)\n",
    "        if automatic_baselines[i] == False:\n",
    "            signal_avg = np.mean(A0s[i][col][np.logical_and(A0s[i][0] > baselines[i][0], A0s[i][0] < baselines[i][1])]) # Dc component of noisy signal\n",
    "            unstim_avg.append(signal_avg)\n",
    "            noise = A0s[i][col][np.logical_and(A0s[i][0] > baselines[i][0], A0s[i][0] < baselines[i][1])] - signal_avg # Ac    \"      \"\n",
    "            thresh = signal_avg + (num_stds[i] * np.std(noise)) # Latency threshold value\n",
    "            response_thresh = signal_avg + (response_stds[i] * np.std(noise)) # Response threshold value\n",
    "            mthresh = signal_avg - (num_stds[i] * np.std(noise)) # Mirror threshold value around signal_avg\n",
    "            ax.fill((baselines[i][0],baselines[i][1],baselines[i][1],baselines[i][0]),(mthresh,mthresh,thresh,thresh),'0.8') # Mark threshold region on plot\n",
    "        \n",
    "        ax.plot(A0s[i][0],A0s[i][col]) # Plot data for this region\n",
    "        \n",
    "        # Setting starting baseline values\n",
    "        if starting_baselines[i] == True:\n",
    "            start_avg = np.mean(A0s[i][col][np.logical_and(A0s[i][0]>(A0s[i][0][0]), A0s[i][0] < (A0s[i][0][0] + start_lengths[i]))])\n",
    "            starting_base[np.where(full_cols[i] == col)] = start_avg\n",
    "        \n",
    "        # Find first peak, latency start point, latency, max slope and area under curve for every zone in this region\n",
    "        # Local variables\n",
    "        idx_fpk = [] # First peak  indices, for this region\n",
    "        idx_lst = [] # Latency start  \"         \"\n",
    "        lats = [] # Latencies         per zone, for this region\n",
    "        riss = [] # Rise times           \"            \"\n",
    "        slps = [] # Maximum slopes       \"            \"\n",
    "        zars = [] # Area under curve     \"            \"\n",
    "        maxs = [] # Maximum values       \"            \"\n",
    "        resp = [] # Whether max is over response threshold   \"           \"\n",
    "        \n",
    "        for z in zn:  # For each zone..\n",
    "            plot_curve = True\n",
    "            if automatic_baselines[i] == True:\n",
    "                baseline = [] # Automatic baseline values\n",
    "                baseline.append(z.value[0] - (base_lengths[i] + 1))\n",
    "                baseline.append(z.value[0] - 1)\n",
    "                signal_avg = np.mean(A0s[i][col][np.logical_and(A0s[i][0] > baseline[0], A0s[i][0] < baseline[1])])  # Dc component of noisy signal\n",
    "                baseline_avgs.append(signal_avg)\n",
    "                noise = A0s[i][col][np.logical_and(A0s[i][0] > baseline[0], A0s[i][0] < baseline[1])] - signal_avg   # Ac    \"          \"\n",
    "                thresh = signal_avg + (num_stds[i] * np.std(noise))                                          # Latency threshold value\n",
    "                response_thresh = signal_avg + (response_stds[i] * np.std(noise))                           # Response threshold value\n",
    "                mthresh = signal_avg - (num_stds[i] * np.std(noise))          \n",
    "            zidx = np.where(np.logical_and(A0s[i][0] > z.value[0], A0s[i][0] < z.value[1]))[0] # All indices within zone\n",
    "            pzidx = np.where(A0s[i][col] == np.max(A0s[i][col][zidx])) # Since CPA experiment, only care about maximum point within zone\n",
    "            idxf = -1  # First peak index for this zone\n",
    "            idxl = -1  # Latency start index for this zone\n",
    "            for j in zidx: # Find latency start point in this zone\n",
    "                if A0s[i][col,j] >= thresh:  # If above the threshold\n",
    "                    ax.plot(A0s[i][0,j],A0s[i][col,j],'r.') # Plot the latency start location\n",
    "                    idxl = j\n",
    "                    break\n",
    "            idxf = int(pzidx[0]) # Since CPA experiment, only want first point that is equal to max value within zone\n",
    "            ax.plot(A0s[i][0,idxf],A0s[i][col,idxf],'b.') # Plot maximum point\n",
    "            idx_fpk.append(idxf)                     # Save first peak\n",
    "            idx_lst.append(idxl)                     # Save latency start\n",
    "            # Calculating if over response threshold\n",
    "            if len(np.argwhere(A0s[i][col,zidx]>= response_thresh)) > 2:\n",
    "                resp.append(True)\n",
    "            else:\n",
    "                resp.append(False)\n",
    "             \n",
    "            lat = 0\n",
    "            ris = 0\n",
    "            slp = 0\n",
    "            if (idxf != -1) and (idxl != -1):\n",
    "                lat = A0s[i][0,idxl] - A0s[i][0,zidx[0]] # Save latency time\n",
    "                ris = A0s[i][0,idxf] - A0s[i][0,idxl]     # Save rise time\n",
    "                x_vals = A0s[i][0,idxl:idxf+1]\n",
    "                y_vals = A0s[i][col,idxl:idxf+1]\n",
    "                if slope_types[i] == 1:  # Simple difference calculations\n",
    "                    for j in range(len(x_vals)-1):\n",
    "                        sl = (y_vals[j+1] - y_vals[j]) / (x_vals[j+1] - x_vals[j])\n",
    "                        if sl > slp:\n",
    "                            slp = sl\n",
    "                if slope_types[i] == 2:  # Three neighbor numerical calculations\n",
    "                    if len(x_vals) > 5:\n",
    "                        for j in range(3, len(x_vals) - 3):\n",
    "                            sls = []\n",
    "                            for k in range(1,4):\n",
    "                                y1 = y_vals[j - k]\n",
    "                                y2 = y_vals[j + k]\n",
    "                                x1 = x_vals[j - k]\n",
    "                                x2 = x_vals[j + k]\n",
    "                                sls.append((y2-y1)/(x2-x1))\n",
    "                            sl = np.mean(sls)\n",
    "                            if sl > slp:\n",
    "                                slp = sl\n",
    "                    else:\n",
    "                        print(\"For the following graph, not enough data points for Three Neighbor Numerical, instead using Simple Difference\")\n",
    "                        for j in range(len(x_vals)-1):\n",
    "                            sl = (y_vals[j+1] - y_vals[j]) / (x_vals[j+1] - x_vals[j])\n",
    "                            if sl > slp:\n",
    "                                slp = sl\n",
    "                if slope_types[i] == 3:   # Polynomial fit calculations\n",
    "                    if len(x_vals) > 3:\n",
    "                        popt, pcov = curve_fit(poly, x_vals, y_vals)\n",
    "                        fitted_y_vals = poly(x_vals, *popt)\n",
    "                        ax.plot(x_vals,fitted_y_vals,'r')\n",
    "                        if len(fitted_y_vals) > 3:\n",
    "                            for j in range(1, len(fitted_y_vals)):\n",
    "                                sl = (fitted_y_vals[j] - fitted_y_vals[j - 1]) / (x_vals[j] - x_vals[j-1])\n",
    "                                if sl > slp:\n",
    "                                    slp = sl\n",
    "                    else:\n",
    "                        print(\"For the following graph, not enough data points for Polynomial Fit, instead using Simple Difference\")\n",
    "                        for j in range(len(x_vals)-1):\n",
    "                            sl = (y_vals[j+1] - y_vals[j]) / (x_vals[j+1] - x_vals[j])\n",
    "                            if sl > slp:\n",
    "                                slp = sl    \n",
    "                if slope_types[i] == 4:   # Gaussian fit calculations\n",
    "                    x_vals = A0s[i][0,idxl:idxf+1+len(x_vals)]  # Extend selection of values to be symetrical around the peak\n",
    "                    y_vals = A0s[i][col,idxl:idxf+1+len(y_vals)]\n",
    "                    if len(x_vals) > 6:\n",
    "                        mean = sum(x_vals * y_vals) / sum(y_vals)\n",
    "                        sigma = math.sqrt(sum(y_vals * (x_vals - mean)**2) / sum(y_vals))\n",
    "                        y0 = thresh\n",
    "                        with warnings.catch_warnings():\n",
    "                            warnings.simplefilter(\"error\", OptimizeWarning)\n",
    "                            try:\n",
    "                                popt, pcov = curve_fit(gauss, x_vals, y_vals, p0=[max(y_vals),mean,sigma,y0], maxfev = 5000)\n",
    "                            except RuntimeError:\n",
    "                                print(\"A Gaussian Curve could not be calculated for the following graph, instead using Simple Difference\")\n",
    "                                plot_curve = False # Do not plot curve if cant be calculated\n",
    "                                for j in range(len(x_vals)-1):\n",
    "                                    sl = (y_vals[j+1] - y_vals[j]) / (x_vals[j+1] - x_vals[j])\n",
    "                                    if sl > slp:\n",
    "                                        slp = sl\n",
    "                            except OptimizeWarning:\n",
    "                                print(\"A Gaussian Curve could not be calculated for the following graph, instead using Simple Difference\")\n",
    "                                plot_curve = False # Do not plot curve if cant be calculated\n",
    "                                for j in range(len(x_vals)-1):\n",
    "                                    sl = (y_vals[j+1] - y_vals[j]) / (x_vals[j+1] - x_vals[j])\n",
    "                                    if sl > slp:\n",
    "                                        slp = sl\n",
    "                                \n",
    "                        fitted_y_vals = gauss(x_vals, *popt)\n",
    "                        if plot_curve == True:\n",
    "                            ax.plot(x_vals,fitted_y_vals,'r')\n",
    "                        peak_index = np.where(fitted_y_vals == np.max(fitted_y_vals))  # Find where peak of gaussian curve\n",
    "                        for j in range(1, int(peak_index[0][0])):\n",
    "                            sl = (fitted_y_vals[j] - fitted_y_vals[j - 1]) / (x_vals[j] - x_vals[j - 1])\n",
    "                            if sl > slp:\n",
    "                                slp = sl\n",
    "                    else:\n",
    "                        print(\"For the following graph, not enough data points for Gaussian Curve, instead using Simple Difference\")\n",
    "                        for j in range(len(x_vals)-1):\n",
    "                            sl = (y_vals[j+1] - y_vals[j]) / (x_vals[j+1] - x_vals[j])\n",
    "                            if sl > slp:\n",
    "                                slp = sl\n",
    "            lats.append(lat)\n",
    "            riss.append(ris)\n",
    "            slps.append(slp)\n",
    "            maxs.append(np.amax(A0s[i][col,zidx]) - signal_avg)\n",
    "            if (idxf != -1) and (idxl != -1):\n",
    "                zars.append(np.trapz(A0s[i][col,zidx] - signal_avg, A0s[i][0,zidx]))  # Calculate and save area under curve\n",
    "            else: # If no latency point, zone area is zero \n",
    "                zars.append(0)\n",
    "    \n",
    "        # Finalize and save the region plot\n",
    "        xlab = \"time (s)\\n\"\n",
    "        xlab += (\" areas: [\"+', '.join(['%.3g']*len(zars))+\"]\") % tuple(zars)\n",
    "        xlab += (\", max vals: [\"+', '.join(['%.3g']*len(maxs))+\"]\") % tuple(maxs)\n",
    "        xlab += (\",\\nlatencies: [\"+', '.join(['%.3g']*len(lats))+\"]\") % tuple(lats)\n",
    "        xlab += (\", rise times: [\"+', '.join(['%.3g']*len(riss))+\"]\") % tuple(riss)\n",
    "        xlab += (\", first peak vals: [\"+', '.join(['%.3g']*len(idx_fpk))+\"]\") % tuple([A0s[i][col,x] if x!=-1 else 0 for x in idx_fpk])\n",
    "        xlab += (\",\\nmax slopes: [\"+', '.join(['%.3g']*len(slps))+\"]\") % tuple(slps)\n",
    "            \n",
    "        if automatic_baselines[i] == True:\n",
    "            xlab += (\", unstimulated avg: [\" + ', '.join(['%.3g']*len(baseline_avgs))+\"]\") % tuple(baseline_avgs)\n",
    "        else:\n",
    "            xlab += (\", unstimulated avg: [\" + f'''{signal_avg:.3g}'''+ \"]\")\n",
    "    \n",
    "        if starting_baselines[i] == True:\n",
    "            xlab += (\", starting unstimulated avg: [\" + f'''{start_avg:.3g}'''+ \"]\")\n",
    "            if automatic_baselines[i] == False:\n",
    "                xlab += (\", starting unstimulated avg - unstimulated avg: [\" + f'''{(start_avg-signal_avg):.3g}'''+\"]\")\n",
    "            else:\n",
    "                dif_avgs = start_avg - baseline_avgs # Creating tuple of averages difference\n",
    "                xlab += (\", starting unstimulated avg - unstimulated avg: [\" + ', '.join(['%.3g']*len(baseline_avgs))+\"]\") % tuple(dif_avgs)\n",
    "        ax.set(xlabel=xlab)\n",
    "        plt.savefig(results_dirs[i] + \"/region_\" + str(col) + \".pdf\") # Save figure as pdf\n",
    "        plt.show()\n",
    "        plt.close() # Frees up memory\n",
    "            \n",
    "        idx_fpks.append(idx_fpk) # Save the first peaks across all regions\n",
    "        idx_lsts.append(idx_lst) #  \"       Latency starts     \"\n",
    "        latencies.append(lats)   #  \"       Latencies          \"\n",
    "        rise_times.append(riss)  #  \"       Rise times         \"\n",
    "        max_slopes.append(slps)  #  \"       Maximum slopes     \"\n",
    "        zone_areas.append(zars)  #  \"       Area under curve   \"\n",
    "        max_vals.append(maxs)    #  \"       Maximum values     \"\n",
    "        responding.append(resp)  #  \"       Whether max values are over response threshold \n",
    "    \n",
    "        if automatic_baselines[i] == True:\n",
    "            unstim_avg.append(baseline_avgs)\n",
    "        # Average standard deviation plotting\n",
    "        if included_widgets[i].value == True and col == max(full_cols[i]):\n",
    "            fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(15,3), constrained_layout=True)\n",
    "            ax.grid(visible=True)\n",
    "            ax.set_title(\"Standard deviation of Average of \" + selected_files[i])\n",
    "            ax.set(ylabel=\"340/380nm\")\n",
    "            ax.set(xlabel=\"time (s)\")\n",
    "            ax.plot(A0s[i][0],A0s[i][col], label=\"Average\")\n",
    "            avg_X = A0s[i][0]\n",
    "            avg = A0s[i][col]\n",
    "            pre_std = A0s[i][1:col]\n",
    "            std = pre_std.std(axis=0)\n",
    "            ax.errorbar(avg_X[0::10],avg[0::10],std[0::10], linestyle='None',\n",
    "                        marker='^', label=\"Standard Deviation\") # Std plotting of every 10th point's std\n",
    "            ax.legend(loc = 'best')\n",
    "            plt.savefig(results_dirs[i] + \"/std_average_\" + \".pdf\") # Save figure as pdf\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "    percent_responding = (np.sum(responding,axis=0) / len(full_cols[i])) * 100 # Calculating percentage of ROIS that respond in each zone\n",
    "\n",
    " # Save peak counts and optional latency summaries to CSV file\n",
    "    if automatic_baselines[i] == False and starting_baselines[i] == False:\n",
    "        with open (results_dirs[i] + \"/total_data_by_zone.csv\", 'w',newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow((\"region number\", \"peak value\", \"areas\", \"maximum values (peak value with baseline subtracted)\", \"latencies\", \"rise times\", \n",
    "                             \"maximum slopes\", \"unstimulated average\", \"responding percentage (by zone)\"))\n",
    "            for j in range(len(zone_areas[0])):\n",
    "                writer.writerow((\"\"))\n",
    "                for k in range(len(full_cols[i])):\n",
    "                    r = (full_cols[i][k], A0s[i][full_cols[i][k],idx_fpks[k][j]] if idx_fpks[k][j]!=-1 else 0,\n",
    "                         zone_areas[k][j], max_vals[k][j], latencies[k][j],\n",
    "                         rise_times[k][j], max_slopes[k][j], unstim_avg[k], percent_responding[j])\n",
    "                    writer.writerow('{:.3g}'.format(x) for x in tuple(r))\n",
    "                \n",
    "    elif automatic_baselines[i] == True and starting_baselines[i] == True:\n",
    "        with open (results_dirs[i] + \"/total_data_by_zone.csv\", 'w',newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow((\"region number\", \"peak value\", \"areas\", \"maximum values (peak value with baseline subtracted)\", \"latencies\", \n",
    "                             \"rise times\", \"maximum slopes\", \"unstimulated average\", \n",
    "                             \"starting unstimulated average\", \"difference of starting and unstim\", \"responding percentage (by zone)\"))\n",
    "            for j in range(len(zone_areas[0])):\n",
    "                writer.writerow((\"\"))\n",
    "                for k in range(len(full_cols[i])):\n",
    "                    r = (full_cols[i][k], A0s[i][full_cols[i][k],idx_fpks[k][j]] if idx_fpks[k][j]!=-1 else 0,\n",
    "                         zone_areas[k][j], max_vals[k][j], latencies[k][j], rise_times[k][j], max_slopes[k][j], \n",
    "                         unstim_avg[k][j], starting_base[k], (starting_base[k] - unstim_avg[k][j]), percent_responding[j])\n",
    "                    writer.writerow('{:.3g}'.format(x) for x in tuple(r))\n",
    "    elif automatic_baselines[i] == True and starting_baselines[i] == False:\n",
    "        with open (results_dirs[i] + \"/total_data_by_zone.csv\", 'w',newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow((\"region number\", \"peak value\", \"areas\", \"maximum values (peak value with baseline subtracted)\", \"latencies\", \"rise times\", \n",
    "                             \"maximum slopes\", \"unstimulated average\", \"responding percentage (by zone)\"))\n",
    "            for j in range(len(zone_areas[0])):\n",
    "                writer.writerow((\"\"))\n",
    "                for k in range(len(full_cols[i])):\n",
    "                    r = (full_cols[i][k], A0s[i][full_cols[i][k], idx_fpks[k][j]] if idx_fpks[k][j]!=-1 else 0,\n",
    "                         zone_areas[k][j], max_vals[k][j], latencies[k][j], \n",
    "                         rise_times[k][j], max_slopes[k][j], unstim_avg[k][j], percent_responding[j])\n",
    "                    writer.writerow('{:.3g}'.format(x) for x in tuple(r))\n",
    "    else:\n",
    "        with open (results_dirs[i] + \"/total_data_by_zone.csv\", 'w',newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow((\"region number\", \"peak value\", \"areas\", \"maximum values (peak value with baseline subtracted)\",\n",
    "                             \"latencies\",\"rise times\", \"maximum slopes\", \"unstimulated average\", \n",
    "                             \"starting unstimulated average\", \"difference of starting and unstim\", \"responding percentage (by zone)\"))\n",
    "            for j in range(len(zone_areas[0])):\n",
    "                writer.writerow((\"\"))\n",
    "                for k in range(len(full_cols[i])):\n",
    "                    r = (full_cols[i][k], A0s[i][full_cols[i][k], idx_fpks[k][j]] if idx_fpks[k][j]!=-1 else 0,\n",
    "                         zone_areas[k][j], max_vals[k][j], latencies[k][j], rise_times[k][j], max_slopes[k][j], \n",
    "                         unstim_avg[k], starting_base[k], (starting_base[k] - unstim_avg[k][j]), percent_responding[j])\n",
    "                    writer.writerow('{:.3g}'.format(x) for x in tuple(r))\n",
    "\n",
    "    # save standard deviation of average values to CSV file\n",
    "    if included_widgets[i].value == True: # If avg column is included show standard deviation from avg\n",
    "        with open(results_dirs[i] + \"/std_average_\" + \".csv\", 'w',newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow((\"time\",\"average\",\"standard deviation\"))\n",
    "            for x in range(len(A0s[i][0])):\n",
    "                r = (avg_X[x], avg[x], std[x])\n",
    "                writer.writerow('{:.3g}'.format(x) for x in tuple(r)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
